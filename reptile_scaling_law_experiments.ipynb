{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Investigating Scaling Laws in Meta-Learning with LLMs\n",
        "\n",
        "## Project: Reptile Meta-Learning on Banking77\n",
        "\n",
        "**Research Question**: Does meta-learning performance follow a power law?\n",
        "\n",
        "$$L_{\\text{meta}} \\propto N_{\\text{tasks}}^{-\\beta}$$\n",
        "\n",
        "### Setup:\n",
        "- **Dataset**: Banking77 (77 intent classes)\n",
        "- **Model**: TinyLlama-1.1B with LoRA\n",
        "- **Meta-learning**: Reptile (First-order MAML)\n",
        "- **Task**: 5-way 5-shot classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "Install required packages and import modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "from datetime import datetime\n",
        "\n",
        "# Import our modules\n",
        "from llm_model import LLMLoRAClassifier\n",
        "from banking77_data import Banking77TaskSampler\n",
        "from reptile_trainer import ReptileLLMTrainer\n",
        "from experiment_runner import ScalingLawExperimentRunner, run_pilot_experiment\n",
        "from evaluation import evaluate_baseline_no_meta, evaluate_zero_shot\n",
        "\n",
        "print(\"✓ All modules imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"Number of GPUs: {torch.cuda.device_count()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Configuration\n",
        "\n",
        "Set up experimental configuration for scaling law investigation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "CONFIG = {\n",
        "    'model_name': 'TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
        "    'n_way': 5,\n",
        "    'k_support': 5,\n",
        "    'k_query': 15,\n",
        "    'max_length': 64,\n",
        "    'lora_r': 16,\n",
        "    'lora_alpha': 32,\n",
        "    'lora_dropout': 0.05,\n",
        "    'inner_lr': 5e-4,\n",
        "    'meta_lr': 0.1,\n",
        "    'k_inner': 5,\n",
        "    'meta_batch_size': 4,\n",
        "    'inner_batch_size': 25,\n",
        "    'num_meta_steps': 10000,\n",
        "    'eval_interval': 500,\n",
        "    'num_eval_tasks': 100,\n",
        "    'num_meta_test_tasks': 200,\n",
        "    'devices': ['cuda:4', 'cuda:5', 'cuda:6', 'cuda:7'],\n",
        "    'load_in_8bit': False,\n",
        "    'seed_meta_test': 0,\n",
        "    'seed_train_base': 100\n",
        "}\n",
        "\n",
        "N_TASKS_LIST = [50, 100, 300, 1000]\n",
        "\n",
        "print(\"Configuration set!\")\n",
        "print(f\"N_tasks to test: {N_TASKS_LIST}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Main Experiment: Run Scaling Law Investigation\n",
        "\n",
        "This will run experiments for all N_tasks values (50, 100, 300, 1000).\n",
        "\n",
        "**WARNING**: This takes ~20-25 hours on 4 GPUs!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize experiment runner\n",
        "runner = ScalingLawExperimentRunner(\n",
        "    model_name=CONFIG['model_name'],\n",
        "    n_tasks_list=N_TASKS_LIST,\n",
        "    base_config=CONFIG,\n",
        "    seed_meta_test=CONFIG['seed_meta_test'],\n",
        "    seed_train_base=CONFIG['seed_train_base'],\n",
        "    save_root='./experiments_scaling_law',\n",
        "    devices=CONFIG['devices']\n",
        ")\n",
        "\n",
        "# Run all experiments\n",
        "runner.run_all_experiments()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Results Analysis\n",
        "\n",
        "Load and visualize the scaling law results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "# Load results\n",
        "results_df = pd.read_csv('./experiments_scaling_law/scaling_law_results.csv')\n",
        "print(\"Results:\")\n",
        "print(results_df)\n",
        "\n",
        "# Load power law fit\n",
        "with open('./experiments_scaling_law/power_law_fit.json', 'r') as f:\n",
        "    power_law_fit = json.load(f)\n",
        "\n",
        "print(f\"\\nPower Law: {power_law_fit['formula']}\")\n",
        "print(f\"β = {power_law_fit['beta']:.6f}, R² = {power_law_fit['R_squared']:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize scaling law\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Log-log plot\n",
        "ax = axes[0]\n",
        "ax.errorbar(results_df['n_tasks'], results_df['meta_test_loss'], \n",
        "            yerr=results_df['meta_test_loss_std'],\n",
        "            marker='o', markersize=8, capsize=5, linewidth=2)\n",
        "n_range = np.logspace(np.log10(results_df['n_tasks'].min()), \n",
        "                      np.log10(results_df['n_tasks'].max()), 100)\n",
        "loss_fit = power_law_fit['A'] * (n_range ** (-power_law_fit['beta']))\n",
        "ax.plot(n_range, loss_fit, 'r--', linewidth=2, \n",
        "        label=f\"β={power_law_fit['beta']:.3f}\")\n",
        "ax.set_xlabel('N_tasks', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Meta-Test Loss', fontsize=12, fontweight='bold')\n",
        "ax.set_xscale('log')\n",
        "ax.set_yscale('log')\n",
        "ax.set_title('Scaling Law: Loss ~ N^(-β)', fontsize=14)\n",
        "ax.legend()\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "ax = axes[1]\n",
        "ax.errorbar(results_df['n_tasks'], results_df['meta_test_accuracy'], \n",
        "            yerr=results_df['meta_test_accuracy_std'],\n",
        "            marker='s', markersize=8, capsize=5, color='green', linewidth=2)\n",
        "ax.set_xlabel('N_tasks', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Meta-Test Accuracy', fontsize=12, fontweight='bold')\n",
        "ax.set_xscale('log')\n",
        "ax.set_title('Accuracy vs N_tasks', fontsize=14)\n",
        "ax.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
